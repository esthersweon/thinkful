{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge: Build your own NLP model\n",
    "\n",
    "Choose a corpus of data from nltk or another source that includes categories you can predict and create an analysis pipeline that includes the following steps:\n",
    "\n",
    "- Data cleaning / processing / language parsing\n",
    "- Create features using two different NLP methods: For example, BoW vs tf-idf.\n",
    "- Use the features to fit supervised learning models for each feature set to predict the category outcomes.\n",
    "- Assess your models using cross-validation and determine whether one model performed better.\n",
    "- Pick one of the models and try to increase accuracy by at least 5 percentage points.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Categories:\n",
      "      ['adventure', 'belles_lettres', 'editorial', 'fiction', 'government', 'hobbies', 'humor', 'learned', 'lore', 'mystery', 'news', 'religion', 'reviews', 'romance', 'science_fiction']\n",
      "*** Adventure Words:\n",
      "      ['Dan', 'Morgan', 'told', 'himself', 'he', 'would', ...]\n",
      "*** Romance and Sci-Fi Sentences:\n",
      "      [['Now', 'that', 'he', 'knew', 'himself', 'to', 'be', 'self', 'he', 'was', 'free', 'to', 'grok', 'ever', 'closer', 'to', 'his', 'brothers', ',', 'merge', 'without', 'let', '.'], [\"Self's\", 'integrity', 'was', 'and', 'is', 'and', 'ever', 'had', 'been', '.'], ...]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from nltk.corpus import brown, stopwords\n",
    "from collections import Counter\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "print('*** Categories:\\n     ', brown.categories())\n",
    "print('*** Adventure Words:\\n     ', brown.words(categories='adventure'))\n",
    "print('*** Romance and Sci-Fi Sentences:\\n     ', brown.sents(categories=['romance', 'science_fiction']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and Language Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** humor ***\n",
      "      [['It was among these that Hinkle identified a photograph of Barco ! !', ['-pron-', 'hinkle', 'identify', 'photograph', 'barco']], [\"For it seems that Barco , fancying himself a ladies' man ( and why not , after seven marriages ? ?\", ['for', 'barco', 'fancy', 'lady', 'man', 'seven', 'marriage']]]\n",
      "*** science_fiction ***\n",
      "      [['Now that he knew himself to be self he was free to grok ever closer to his brothers , merge without let .', ['now', 'know', 'self', 'free', 'grok', 'closer', 'brother', 'merge', 'let']], [\"Self's integrity was and is and ever had been .\", ['self', \"'s\", 'integrity']]]\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en')\n",
    "\n",
    "def text_cleaner(text):\n",
    "    text = re.sub(r'--',' ',text)\n",
    "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "all_category_texts = {}\n",
    "for category in ['humor', 'science_fiction']:\n",
    "    current_categorys_lemmatized_sents = []\n",
    "    category_sentences = brown.sents(categories=category)\n",
    "    for original_sent in category_sentences:\n",
    "        sent = text_cleaner(' '.join(original_sent))\n",
    "        sent_doc = nlp(sent)\n",
    "        sent = [\n",
    "            token.lemma_.lower()\n",
    "            for token in sent_doc\n",
    "            if not token.is_stop\n",
    "            and not token.is_punct\n",
    "        ]\n",
    "        current_categorys_lemmatized_sents.append([' '.join(original_sent), sent])\n",
    "    all_category_texts[category] = current_categorys_lemmatized_sents\n",
    "\n",
    "for genre, sentences in all_category_texts.items():\n",
    "    print('***', genre, '***\\n     ', sentences[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2001, 3)\n",
      "humor              1053\n",
      "science_fiction     948\n",
      "Name: genre, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It was among these that Hinkle identified a ph...</td>\n",
       "      <td>[-pron-, hinkle, identify, photograph, barco]</td>\n",
       "      <td>humor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>For it seems that Barco , fancying himself a l...</td>\n",
       "      <td>[for, barco, fancy, lady, man, seven, marriage]</td>\n",
       "      <td>humor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>) , had listed himself for Mormon Beard roles ...</td>\n",
       "      <td>[list, mormon, beard, rol, instigation, fourth...</td>\n",
       "      <td>humor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mills secured Barco's photograph from the gent...</td>\n",
       "      <td>[mill, secure, barco, 's, photograph, gentlema...</td>\n",
       "      <td>humor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>On their way , they stopped at every gas stati...</td>\n",
       "      <td>[on, way, stop, gas, station, main, boulevard,...</td>\n",
       "      <td>humor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            original  \\\n",
       "0  It was among these that Hinkle identified a ph...   \n",
       "1  For it seems that Barco , fancying himself a l...   \n",
       "2  ) , had listed himself for Mormon Beard roles ...   \n",
       "3  Mills secured Barco's photograph from the gent...   \n",
       "4  On their way , they stopped at every gas stati...   \n",
       "\n",
       "                                              lemmas  genre  \n",
       "0      [-pron-, hinkle, identify, photograph, barco]  humor  \n",
       "1    [for, barco, fancy, lady, man, seven, marriage]  humor  \n",
       "2  [list, mormon, beard, rol, instigation, fourth...  humor  \n",
       "3  [mill, secure, barco, 's, photograph, gentlema...  humor  \n",
       "4  [on, way, stop, gas, station, main, boulevard,...  humor  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sentence_rows = []\n",
    "for genre, genre_sentences in all_category_texts.items():\n",
    "    sentence_row = [[sent[0], sent[1], genre] for sent in genre_sentences]\n",
    "    all_sentence_rows = all_sentence_rows + sentence_row\n",
    "\n",
    "sentences_df = pd.DataFrame(all_sentence_rows, columns=['original', 'lemmas', 'genre'])\n",
    "print(sentences_df.shape)\n",
    "print(sentences_df['genre'].value_counts())\n",
    "sentences_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Feature Engineering\n",
    "\n",
    "### Strategy 1 - Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Creating bag for humor\n",
      "*** Creating bag for science_fiction\n",
      "73 Common Words: {'jack', 'old', 'good', 'letch', 'half', 'look', 'find', 'take', '-pron-', 'girl', 'welch', 'know', 'call', 'mother', 'head', 'thing', 'think', 'say', 'light', 'course', \"'s\", 'funny', 'a', 'mike', \"b'dikkat\", 'speak', 'ask', 'little', 'new', 'turn', 'go', 'shell', '``', 'grow', 'have', 'mr.', 'there', 'long', 'ship', 'time', 'day', 'people', 'year', 'feel', 'hal', 'room', 'tell', 'man', 'arlene', 'child', 'barco', 'non', 'and', 'mercer', 'earth', 'be', 'mind', 'body', 'word', 'the', 'but', 'what', 'ekstrohm', 'come', 'as', 'no', 'get', 'like', 'in', 'helva', 'not', 'work', 'way'}\n",
      "Processing row 0\n",
      "Processing row 500\n",
      "Processing row 1000\n",
      "Processing row 1500\n",
      "Processing row 2000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jack</th>\n",
       "      <th>old</th>\n",
       "      <th>good</th>\n",
       "      <th>letch</th>\n",
       "      <th>half</th>\n",
       "      <th>look</th>\n",
       "      <th>find</th>\n",
       "      <th>take</th>\n",
       "      <th>-pron-</th>\n",
       "      <th>girl</th>\n",
       "      <th>...</th>\n",
       "      <th>get</th>\n",
       "      <th>like</th>\n",
       "      <th>in</th>\n",
       "      <th>helva</th>\n",
       "      <th>not</th>\n",
       "      <th>work</th>\n",
       "      <th>way</th>\n",
       "      <th>original</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>It was among these that Hinkle identified a ph...</td>\n",
       "      <td>[-pron-, hinkle, identify, photograph, barco]</td>\n",
       "      <td>humor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>For it seems that Barco , fancying himself a l...</td>\n",
       "      <td>[for, barco, fancy, lady, man, seven, marriage]</td>\n",
       "      <td>humor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>) , had listed himself for Mormon Beard roles ...</td>\n",
       "      <td>[list, mormon, beard, rol, instigation, fourth...</td>\n",
       "      <td>humor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Mills secured Barco's photograph from the gent...</td>\n",
       "      <td>[mill, secure, barco, 's, photograph, gentlema...</td>\n",
       "      <td>humor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>On their way , they stopped at every gas stati...</td>\n",
       "      <td>[on, way, stop, gas, station, main, boulevard,...</td>\n",
       "      <td>humor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  jack old good letch half look find take -pron- girl  ...   get like in  \\\n",
       "0    0   0    0     0    0    0    0    0      1    0  ...     0    0  0   \n",
       "1    0   0    0     0    0    0    0    0      0    0  ...     0    0  0   \n",
       "2    0   0    0     0    0    0    0    0      0    0  ...     0    0  0   \n",
       "3    0   0    0     0    0    0    0    0      0    0  ...     0    0  0   \n",
       "4    0   0    0     0    0    0    0    0      0    0  ...     0    0  0   \n",
       "\n",
       "  helva not work way                                           original  \\\n",
       "0     0   0    0   0  It was among these that Hinkle identified a ph...   \n",
       "1     0   0    0   0  For it seems that Barco , fancying himself a l...   \n",
       "2     0   0    0   0  ) , had listed himself for Mormon Beard roles ...   \n",
       "3     0   0    0   0  Mills secured Barco's photograph from the gent...   \n",
       "4     0   0    0   1  On their way , they stopped at every gas stati...   \n",
       "\n",
       "                                              lemmas  genre  \n",
       "0      [-pron-, hinkle, identify, photograph, barco]  humor  \n",
       "1    [for, barco, fancy, lady, man, seven, marriage]  humor  \n",
       "2  [list, mormon, beard, rol, instigation, fourth...  humor  \n",
       "3  [mill, secure, barco, 's, photograph, gentlema...  humor  \n",
       "4  [on, way, stop, gas, station, main, boulevard,...  humor  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of 100 most common words\n",
    "def bag_of_words(all_lemmas):\n",
    "    return [item[0] for item in Counter(all_lemmas).most_common(50)]\n",
    "    \n",
    "# Create df with features for each word in our common word set\n",
    "# Each value is the count of the times the word appears in each sentence\n",
    "def bow_features(sentences_df, common_words):\n",
    "    df = pd.DataFrame(columns=common_words)\n",
    "    df['original'] = sentences_df['original']\n",
    "    df['lemmas'] = sentences_df['lemmas']\n",
    "    df['genre'] = sentences_df['genre']\n",
    "    df.loc[:, common_words] = 0\n",
    "    \n",
    "    # Process each row, counting the occurrence of words in each sentence.\n",
    "    for i, lemmas in enumerate(df['lemmas']):\n",
    "        lemmas = [lemma for lemma in lemmas if lemma in common_words]\n",
    "        for lemma in lemmas:\n",
    "            df.loc[i, lemma] += 1\n",
    "        \n",
    "        if i % 500 == 0:\n",
    "            print(\"Processing row {}\".format(i))\n",
    "            \n",
    "    return df\n",
    "\n",
    "all_bows = []\n",
    "\n",
    "# Set up each genres bags\n",
    "for genre, sentences in all_category_texts.items():\n",
    "    print('*** Creating bag for', genre)\n",
    "    all_lemmas = list(map(lambda sent: sent[1], sentences))\n",
    "    all_lemmas = list(lemma for sent_of_lemmas in all_lemmas for lemma in sent_of_lemmas)\n",
    "    bow = bag_of_words(all_lemmas)\n",
    "    all_bows = all_bows + bow\n",
    "\n",
    "# Combine bags for set of unique words\n",
    "common_words = set(all_bows)\n",
    "print(len(common_words), 'Common Words:', common_words)\n",
    "word_counts = bow_features(sentences_df, common_words)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy 2 - tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 features: ['angel', 'ask', 'body', 'brain', 'brother', 'central', 'come', 'course', 'day', 'dikkat', 'earth', 'ekstrohm', 'eye', 'face', 'feel', 'gabriel', 'good', 'grow', 'hal', 'half', 'hand', 'happen', 'happy', 'head', 'help', 'helva', 'hesperus', 'jack', 'jubal', 'know', 'lady', 'lie', 'light', 'like', 'little', 'live', 'long', 'look', 'man', 'mean', 'mercer', 'mike', 'mind', 'need', 'night', 'people', 'planet', 'power', 'ryan', 'say', 'shell', 'ship', 'sleep', 'sound', 'speak', 'tell', 'thing', 'think', 'time', 'turn', 'want', 'way', 'word', 'work', 'year']\n",
      "\n",
      "Original sentence: ['now know self free grok closer brother merge let', \"self 's integrity\", 'mike stop cherish brother selv three fulfil mars corporate discorporate precious earth unknown power earth merge cherish long wait grokk cherish', 'mike remain trance', 'grok loose end puzzle fit grow see hear archangel foster tabernacle cusp digby come face face bishop senator boone warily uneasy miss dawn ardent taste like water brother smell goodness incompletely grokk jumping wail', \"jubal 's conversation come go jubal 's word trouble\"]\n",
      "Tf_idf vector: [{'know': 0.6001007004191924, 'brother': 0.7999244647817658}, {}, {'brother': 0.3791503103908879, 'mike': 0.33422712529405285, 'earth': 0.7062383997775622, 'power': 0.3791503103908879, 'long': 0.31938947330538053}, {'mike': 1.0}, {'brother': 0.37096771495059466, 'grow': 0.34549839232063995, 'come': 0.33749223651530086, 'face': 0.7301064489764932, 'like': 0.30993124854235493}, {'come': 0.38304983486064276, 'jubal': 0.8286624830211666, 'word': 0.4081559913151207}]\n"
     ]
    }
   ],
   "source": [
    "just_sentences = list(map(lambda sent: ' '.join(sent[1]), sentences))\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.1, min_df=0.01, stop_words='english', lowercase=True, use_idf=True, norm=u'l2', smooth_idf=True)\n",
    "sentences_tfidf = vectorizer.fit_transform(just_sentences)\n",
    "sentences_tfidf_csr = sentences_tfidf.tocsr()\n",
    "\n",
    "num_sentences = sentences_tfidf_csr.shape[0]\n",
    "tfidf_by_sent = [{} for _ in range(0,num_sentences)]\n",
    "\n",
    "terms = vectorizer.get_feature_names()\n",
    "print(len(terms), 'features:', terms)\n",
    "\n",
    "for i, j in zip(*sentences_tfidf_csr.nonzero()):\n",
    "    tfidf_by_sent[i][terms[j]] = sentences_tfidf_csr[i, j]\n",
    "\n",
    "print('\\nOriginal sentence:', just_sentences[:6])\n",
    "print('Tf_idf vector:', tfidf_by_sent[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf_angel</th>\n",
       "      <th>tfidf_ask</th>\n",
       "      <th>tfidf_body</th>\n",
       "      <th>tfidf_brain</th>\n",
       "      <th>tfidf_brother</th>\n",
       "      <th>tfidf_central</th>\n",
       "      <th>tfidf_come</th>\n",
       "      <th>tfidf_course</th>\n",
       "      <th>tfidf_day</th>\n",
       "      <th>tfidf_dikkat</th>\n",
       "      <th>...</th>\n",
       "      <th>tfidf_time</th>\n",
       "      <th>tfidf_turn</th>\n",
       "      <th>tfidf_want</th>\n",
       "      <th>tfidf_way</th>\n",
       "      <th>tfidf_word</th>\n",
       "      <th>tfidf_work</th>\n",
       "      <th>tfidf_year</th>\n",
       "      <th>original</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1e-10</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>0.799924</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>...</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>It was among these that Hinkle identified a ph...</td>\n",
       "      <td>[-pron-, hinkle, identify, photograph, barco]</td>\n",
       "      <td>humor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1e-10</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>...</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>For it seems that Barco , fancying himself a l...</td>\n",
       "      <td>[for, barco, fancy, lady, man, seven, marriage]</td>\n",
       "      <td>humor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1e-10</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>0.37915</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>...</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>) , had listed himself for Mormon Beard roles ...</td>\n",
       "      <td>[list, mormon, beard, rol, instigation, fourth...</td>\n",
       "      <td>humor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1e-10</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>...</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>Mills secured Barco's photograph from the gent...</td>\n",
       "      <td>[mill, secure, barco, 's, photograph, gentlema...</td>\n",
       "      <td>humor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1e-10</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>0.370968</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>0.337492</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>...</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>On their way , they stopped at every gas stati...</td>\n",
       "      <td>[on, way, stop, gas, station, main, boulevard,...</td>\n",
       "      <td>humor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  tfidf_angel tfidf_ask tfidf_body tfidf_brain tfidf_brother tfidf_central  \\\n",
       "0       1e-10     1e-10      1e-10       1e-10      0.799924         1e-10   \n",
       "1       1e-10     1e-10      1e-10       1e-10         1e-10         1e-10   \n",
       "2       1e-10     1e-10      1e-10       1e-10       0.37915         1e-10   \n",
       "3       1e-10     1e-10      1e-10       1e-10         1e-10         1e-10   \n",
       "4       1e-10     1e-10      1e-10       1e-10      0.370968         1e-10   \n",
       "\n",
       "  tfidf_come tfidf_course tfidf_day tfidf_dikkat  ...   tfidf_time tfidf_turn  \\\n",
       "0      1e-10        1e-10     1e-10        1e-10  ...        1e-10      1e-10   \n",
       "1      1e-10        1e-10     1e-10        1e-10  ...        1e-10      1e-10   \n",
       "2      1e-10        1e-10     1e-10        1e-10  ...        1e-10      1e-10   \n",
       "3      1e-10        1e-10     1e-10        1e-10  ...        1e-10      1e-10   \n",
       "4   0.337492        1e-10     1e-10        1e-10  ...        1e-10      1e-10   \n",
       "\n",
       "  tfidf_want tfidf_way tfidf_word tfidf_work tfidf_year  \\\n",
       "0      1e-10     1e-10      1e-10      1e-10      1e-10   \n",
       "1      1e-10     1e-10      1e-10      1e-10      1e-10   \n",
       "2      1e-10     1e-10      1e-10      1e-10      1e-10   \n",
       "3      1e-10     1e-10      1e-10      1e-10      1e-10   \n",
       "4      1e-10     1e-10      1e-10      1e-10      1e-10   \n",
       "\n",
       "                                            original  \\\n",
       "0  It was among these that Hinkle identified a ph...   \n",
       "1  For it seems that Barco , fancying himself a l...   \n",
       "2  ) , had listed himself for Mormon Beard roles ...   \n",
       "3  Mills secured Barco's photograph from the gent...   \n",
       "4  On their way , they stopped at every gas stati...   \n",
       "\n",
       "                                              lemmas  genre  \n",
       "0      [-pron-, hinkle, identify, photograph, barco]  humor  \n",
       "1    [for, barco, fancy, lady, man, seven, marriage]  humor  \n",
       "2  [list, mormon, beard, rol, instigation, fourth...  humor  \n",
       "3  [mill, secure, barco, 's, photograph, gentlema...  humor  \n",
       "4  [on, way, stop, gas, station, main, boulevard,...  humor  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_terms = list(map(lambda term: 'tfidf_' + term, terms))\n",
    "\n",
    "tfidf_df = pd.DataFrame(columns=tfidf_terms)\n",
    "tfidf_df['original'] = sentences_df['original']\n",
    "tfidf_df['lemmas'] = sentences_df['lemmas']\n",
    "tfidf_df['genre'] = sentences_df['genre']\n",
    "tfidf_df.loc[:, tfidf_terms] = 0.0000000001\n",
    "\n",
    "for idx, each_dict in enumerate(tfidf_by_sent):\n",
    "    for keyword, val in each_dict.items():\n",
    "        tfidf_df.loc[idx, 'tfidf_' + keyword] = tfidf_by_sent[idx][keyword]\n",
    "\n",
    "tfidf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2001, 141)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>'s</th>\n",
       "      <th>-pron-</th>\n",
       "      <th>``</th>\n",
       "      <th>a</th>\n",
       "      <th>and</th>\n",
       "      <th>arlene</th>\n",
       "      <th>as</th>\n",
       "      <th>ask</th>\n",
       "      <th>b'dikkat</th>\n",
       "      <th>barco</th>\n",
       "      <th>...</th>\n",
       "      <th>thing</th>\n",
       "      <th>think</th>\n",
       "      <th>time</th>\n",
       "      <th>turn</th>\n",
       "      <th>way</th>\n",
       "      <th>welch</th>\n",
       "      <th>what</th>\n",
       "      <th>word</th>\n",
       "      <th>work</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 141 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   's  -pron-  ``  a  and  arlene  as  ask  b'dikkat  barco  ...   thing  \\\n",
       "0   0       1   0  0    0       0   0    0         0      1  ...       0   \n",
       "1   0       0   0  0    0       0   0    0         0      1  ...       0   \n",
       "2   0       0   1  0    0       0   0    0         0      0  ...       0   \n",
       "3   1       0   0  0    0       0   0    0         0      2  ...       0   \n",
       "4   0       0   0  0    0       0   0    0         0      0  ...       0   \n",
       "\n",
       "   think  time  turn  way  welch  what  word  work  year  \n",
       "0      0     0     0    0      0     0     0     0     0  \n",
       "1      0     0     0    0      0     0     0     0     0  \n",
       "2      0     0     0    0      0     0     0     0     0  \n",
       "3      0     0     0    0      0     0     0     0     0  \n",
       "4      0     0     0    1      0     0     0     0     0  \n",
       "\n",
       "[5 rows x 141 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole_df = word_counts.combine_first(tfidf_df)\n",
    "print(whole_df.shape)\n",
    "whole_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning Models\n",
    "\n",
    "### BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_Y = word_counts['genre']\n",
    "bow_X = np.array(word_counts.drop(['original','lemmas', 'genre'], 1))\n",
    "\n",
    "bow_rfc = ensemble.RandomForestClassifier()\n",
    "bow_lr = LogisticRegression()\n",
    "bow_clf = ensemble.GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_Y = tfidf_df['genre']\n",
    "tfidf_X = np.array(tfidf_df.drop(['original','lemmas', 'genre'], 1))\n",
    "\n",
    "tfidf_rfc = ensemble.RandomForestClassifier()\n",
    "tfidf_lr = LogisticRegression()\n",
    "tfidf_clf = ensemble.GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Both BoW and tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_Y = whole_df['genre']\n",
    "whole_X = np.array(whole_df.drop(['original','lemmas', 'genre'], 1))\n",
    "\n",
    "whole_rfc = ensemble.RandomForestClassifier()\n",
    "whole_lr = LogisticRegression()\n",
    "whole_clf = ensemble.GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "### BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier: [0.58104738 0.57356608 0.6084788  0.5914787  0.53634085]\n",
      "Logistic Regression: [0.52618454 0.6159601  0.63341646 0.61654135 0.55889724]\n",
      "Gradient Boosting Classifier: [0.54114713 0.6084788  0.58852868 0.63157895 0.55889724]\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest Classifier:', cross_val_score(bow_rfc, bow_X, bow_Y, cv=5))\n",
    "print('Logistic Regression:', cross_val_score(bow_lr, bow_X, bow_Y, cv=5))\n",
    "print('Gradient Boosting Classifier:', cross_val_score(bow_clf, bow_X, bow_Y, cv=5))\n",
    "\n",
    "bow_rfc.fit(bow_X, bow_Y)\n",
    "\n",
    "bow_cols_to_note = []\n",
    "for col, feature_imp in zip(word_counts.columns, bow_rfc.feature_importances_):\n",
    "    if feature_imp > 0.019:\n",
    "        bow_cols_to_note.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jack',\n",
       " '-pron-',\n",
       " \"'s\",\n",
       " '``',\n",
       " 'ship',\n",
       " 'hal',\n",
       " 'man',\n",
       " 'mercer',\n",
       " 'be',\n",
       " 'the',\n",
       " 'ekstrohm',\n",
       " 'helva',\n",
       " 'not']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_cols_to_note"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier: [0.72319202 0.78553616 0.78304239 0.81453634 0.6641604 ]\n",
      "Logistic Regression: [0.74064838 0.79551122 0.78553616 0.81453634 0.66917293]\n",
      "Gradient Boosting Classifier: [0.69825436 0.73316708 0.72817955 0.77694236 0.65914787]\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest Classifier:', cross_val_score(tfidf_rfc, tfidf_X, tfidf_Y, cv=5))\n",
    "print('Logistic Regression:', cross_val_score(tfidf_lr, tfidf_X, tfidf_Y, cv=5))\n",
    "print('Gradient Boosting Classifier:', cross_val_score(tfidf_clf, tfidf_X, tfidf_Y, cv=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Both BoW and tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier: [0.6957606  0.72568579 0.75062344 0.76942356 0.68922306]\n",
      "Logistic Regression: [0.73067332 0.74563591 0.77805486 0.8245614  0.66917293]\n",
      "Gradient Boosting Classifier: [0.70074813 0.69077307 0.72069825 0.75689223 0.64411028]\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest Classifier:', cross_val_score(whole_rfc, whole_X, whole_Y, cv=5))\n",
    "print('Logistic Regression:', cross_val_score(whole_lr, whole_X, whole_Y, cv=5))\n",
    "print('Gradient Boosting Classifier:', cross_val_score(whole_clf, whole_X, whole_Y, cv=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Increase Accuracy\n",
    "\n",
    "I will tune the hyperparameters of my Random Forest Classifier for my tf-idf features to increase accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier: [0.74064838 0.78553616 0.78553616 0.81704261 0.66666667]\n"
     ]
    }
   ],
   "source": [
    "tfidf_rfc = ensemble.RandomForestClassifier(n_estimators=100, max_features=5)\n",
    "print('Random Forest Classifier:', cross_val_score(tfidf_rfc, tfidf_X, tfidf_Y, cv=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier: [0.72319202 0.78054863 0.76558603 0.78947368 0.6641604 ]\n"
     ]
    }
   ],
   "source": [
    "new_df = tfidf_df.copy()\n",
    "\n",
    "for col in bow_cols_to_note:\n",
    "    new_df[col] = word_counts[col]\n",
    "    \n",
    "tfidf_Y = new_df['genre']\n",
    "tfidf_X = np.array(new_df.drop(['original','lemmas', 'genre'], 1))\n",
    "\n",
    "tfidf_rfc = ensemble.RandomForestClassifier(n_estimators=100, max_features=5)\n",
    "print('Random Forest Classifier:', cross_val_score(tfidf_rfc, tfidf_X, tfidf_Y, cv=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
