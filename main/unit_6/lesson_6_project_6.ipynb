{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge\n",
    "\n",
    "Now take your Keras skills and go build another neural network. Pick your data set, but it should be one of abstract types, possibly even nonnumeric, and use Keras to make five implementations of your network. Compare them both in computational complexity as well as in accuracy and given that tradeoff decide which one you like best.\n",
    "\n",
    "Your dataset should be sufficiently large for a neural network to perform well (samples should really be in the thousands here) and try to pick something that takes advantage of neural networks’ ability to have both feature extraction and supervised capabilities, so don’t pick something with an easy to consume list of features already generated for you (though neural networks can still be useful in those contexts).\n",
    "\n",
    "Note that if you want to use an unprocessed image dataset, scikit-image is a useful package for converting to importable numerics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3000 [00:00<?, ?it/s]/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "100%|██████████| 3000/3000 [00:11<00:00, 265.39it/s]\n",
      "100%|██████████| 3000/3000 [00:11<00:00, 262.49it/s]\n",
      "100%|██████████| 3000/3000 [00:11<00:00, 261.70it/s]\n",
      "100%|██████████| 3000/3000 [00:11<00:00, 263.18it/s]\n",
      "100%|██████████| 3000/3000 [00:11<00:00, 259.46it/s]\n",
      "100%|██████████| 3000/3000 [00:11<00:00, 258.32it/s]\n",
      "100%|██████████| 3000/3000 [00:11<00:00, 258.37it/s]\n",
      "100%|██████████| 3000/3000 [00:11<00:00, 267.60it/s]\n",
      "100%|██████████| 3000/3000 [00:11<00:00, 254.75it/s]\n",
      "100%|██████████| 3000/3000 [00:11<00:00, 263.82it/s]\n",
      "100%|██████████| 3000/3000 [00:11<00:00, 256.85it/s]\n",
      "100%|██████████| 3000/3000 [00:11<00:00, 255.30it/s]\n",
      "100%|██████████| 3000/3000 [00:11<00:00, 265.89it/s]\n",
      "100%|██████████| 3000/3000 [00:10<00:00, 298.26it/s]\n",
      "100%|██████████| 3000/3000 [00:10<00:00, 285.91it/s]\n",
      "100%|██████████| 3000/3000 [00:10<00:00, 280.35it/s]\n",
      "100%|██████████| 3000/3000 [00:11<00:00, 250.86it/s]\n",
      "100%|██████████| 3000/3000 [00:10<00:00, 282.51it/s]\n",
      "100%|██████████| 3000/3000 [00:10<00:00, 287.10it/s]\n",
      "100%|██████████| 3000/3000 [00:10<00:00, 286.53it/s]\n",
      "100%|██████████| 3000/3000 [00:10<00:00, 289.44it/s]\n",
      "100%|██████████| 3000/3000 [00:10<00:00, 292.43it/s]\n",
      "100%|██████████| 3000/3000 [00:10<00:00, 288.82it/s]\n",
      "100%|██████████| 3000/3000 [00:10<00:00, 289.60it/s]\n",
      "100%|██████████| 3000/3000 [00:10<00:00, 287.31it/s]\n",
      "100%|██████████| 3000/3000 [00:10<00:00, 284.70it/s]\n",
      "100%|██████████| 3000/3000 [00:10<00:00, 284.12it/s]\n",
      "100%|██████████| 3000/3000 [00:10<00:00, 289.09it/s]\n",
      "100%|██████████| 3000/3000 [00:10<00:00, 289.46it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import skimage\n",
    "from skimage import io, transform\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import LSTM, Input\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "img_size = 50\n",
    "train_dir = './data/asl_train/'\n",
    "test_dir =  './data/asl_test/'\n",
    "\n",
    "def get_data(folder_path):\n",
    "    imgs = []\n",
    "    labels = []\n",
    "    for folder_name in os.listdir(folder_path):\n",
    "        if not folder_name.startswith('.'):\n",
    "            if ord(folder_name[0]) >= 65 and ord(folder_name[0]) <= 90:\n",
    "                label = ord(folder_name[0]) - 75\n",
    "            elif folder_name == 'del':\n",
    "                label = 26\n",
    "            elif folder_name == 'nothing':\n",
    "                label = 27\n",
    "            elif folder_name == 'space':\n",
    "                label = 28           \n",
    "            else:\n",
    "                label = 29\n",
    "            for file_name in tqdm(os.listdir(folder_path + folder_name)):\n",
    "                img_file = io.imread(folder_path + folder_name + '/' + file_name)\n",
    "                if img_file is not None:\n",
    "                    img_file = transform.resize(img_file, (img_size, img_size))\n",
    "                    imgs.append(np.asarray(img_file))\n",
    "                    labels.append(label)\n",
    "    imgs = np.asarray(imgs)\n",
    "    labels = np.asarray(labels)\n",
    "    return imgs, labels\n",
    "\n",
    "X_train, y_train = get_data(train_dir)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69600, 50, 50, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69600 train samples\n",
      "17400 test samples\n"
     ]
    }
   ],
   "source": [
    "# 69600 images with 50*50 pixels (2500 pixels total)\n",
    "# 17400 images with 50*50 pixels\n",
    "new_X_train = X_train.reshape(X_train.shape[0], 2500 * 3).astype('float32')\n",
    "new_X_test = X_test.reshape(X_test.shape[0], 2500 * 3).astype('float32')\n",
    "\n",
    "# new_X_train /= 255\n",
    "# new_X_test /= 255\n",
    "\n",
    "print(new_X_train.shape[0], 'train samples')\n",
    "print(new_X_test.shape[0], 'test samples')\n",
    "\n",
    "new_y_train = keras.utils.to_categorical(y_train, 30)\n",
    "new_y_test = keras.utils.to_categorical(y_test, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 100)               750100    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 30)                3030      \n",
      "=================================================================\n",
      "Total params: 763,230\n",
      "Trainable params: 763,230\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(100, activation='relu', input_shape=(2500 * 3,)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(30, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 69600 samples, validate on 17400 samples\n",
      "Epoch 1/10\n",
      "69600/69600 [==============================] - 5s 70us/step - loss: 3.0449 - acc: 0.0973 - val_loss: 2.6786 - val_acc: 0.1447\n",
      "Epoch 2/10\n",
      "69600/69600 [==============================] - 4s 64us/step - loss: 2.6709 - acc: 0.1468 - val_loss: 2.4466 - val_acc: 0.2095\n",
      "Epoch 3/10\n",
      "69600/69600 [==============================] - 5s 69us/step - loss: 2.5086 - acc: 0.1803 - val_loss: 2.2820 - val_acc: 0.2346\n",
      "Epoch 4/10\n",
      "69600/69600 [==============================] - 5s 69us/step - loss: 2.4422 - acc: 0.1967 - val_loss: 2.2004 - val_acc: 0.2652\n",
      "Epoch 5/10\n",
      "69600/69600 [==============================] - 5s 70us/step - loss: 2.3537 - acc: 0.2204 - val_loss: 2.0849 - val_acc: 0.3140\n",
      "Epoch 6/10\n",
      "69600/69600 [==============================] - 5s 70us/step - loss: 2.3032 - acc: 0.2334 - val_loss: 2.1771 - val_acc: 0.2464\n",
      "Epoch 7/10\n",
      "69600/69600 [==============================] - 5s 70us/step - loss: 2.2688 - acc: 0.2401 - val_loss: 2.0975 - val_acc: 0.2879\n",
      "Epoch 8/10\n",
      "69600/69600 [==============================] - 5s 69us/step - loss: 2.2086 - acc: 0.2623 - val_loss: 2.0202 - val_acc: 0.2991\n",
      "Epoch 9/10\n",
      "69600/69600 [==============================] - 5s 70us/step - loss: 2.1747 - acc: 0.2685 - val_loss: 2.0397 - val_acc: 0.2816\n",
      "Epoch 10/10\n",
      "69600/69600 [==============================] - 5s 69us/step - loss: 2.1403 - acc: 0.2764 - val_loss: 1.8729 - val_acc: 0.3508\n",
      "Test loss: 1.872857763301367\n",
      "Test accuracy: 0.3508045977011494\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(new_X_train, new_y_train, batch_size=180, epochs=10, verbose=1, validation_data=(new_X_test, new_y_test))\n",
    "score = model.evaluate(new_X_test, new_y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
