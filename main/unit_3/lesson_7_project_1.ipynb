{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Presentation\n",
    "\n",
    "## Find a dataset of interest\n",
    "\n",
    "I will be investigating a Kaggle dataset gathered from a [Speed Dating Experiment](https://www.kaggle.com/annavictoria/speed-dating-experiment). It was compiled by 2 Columbia Business School professors for their paper \"Gender Differences in Mate Selection: Evidence From a Speed Dating Experiment\", which they wrote in an effort to understand what influences \"love at first sight\".\n",
    "\n",
    "Data was gathered from participants in experimental speed dating events from 2002-2004. During the events, the attendees would have a 4-minute \"first date\" with every other participant of the opposite sex. At the end of their 4 minutes, participants were asked to rate their date on 6 attributes: \n",
    "- Attractiveness\n",
    "- Sincerity\n",
    "- Intelligence\n",
    "- Fun\n",
    "- Ambition\n",
    "- Shared Interests\n",
    "\n",
    "They were also asked if they would like to see their date again.\n",
    "\n",
    "The dataset also includes questionnaire data gathered from participants at different points in the process (i.e. demographics, dating habits, self-perception across key attributes, beliefs on what others find valuable in a mate, and lifestyle information). \n",
    "\n",
    "## Explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8378 Rows\n",
      "195 Columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iid</th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>idg</th>\n",
       "      <th>condtn</th>\n",
       "      <th>wave</th>\n",
       "      <th>round</th>\n",
       "      <th>position</th>\n",
       "      <th>positin1</th>\n",
       "      <th>order</th>\n",
       "      <th>...</th>\n",
       "      <th>attr3_3</th>\n",
       "      <th>sinc3_3</th>\n",
       "      <th>intel3_3</th>\n",
       "      <th>fun3_3</th>\n",
       "      <th>amb3_3</th>\n",
       "      <th>attr5_3</th>\n",
       "      <th>sinc5_3</th>\n",
       "      <th>intel5_3</th>\n",
       "      <th>fun5_3</th>\n",
       "      <th>amb5_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 195 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   iid   id  gender  idg  condtn  wave  round  position  positin1  order  \\\n",
       "0    1  1.0       0    1       1     1     10         7       NaN      4   \n",
       "1    1  1.0       0    1       1     1     10         7       NaN      3   \n",
       "2    1  1.0       0    1       1     1     10         7       NaN     10   \n",
       "3    1  1.0       0    1       1     1     10         7       NaN      5   \n",
       "4    1  1.0       0    1       1     1     10         7       NaN      7   \n",
       "\n",
       "    ...    attr3_3  sinc3_3  intel3_3  fun3_3  amb3_3  attr5_3  sinc5_3  \\\n",
       "0   ...        5.0      7.0       7.0     7.0     7.0      NaN      NaN   \n",
       "1   ...        5.0      7.0       7.0     7.0     7.0      NaN      NaN   \n",
       "2   ...        5.0      7.0       7.0     7.0     7.0      NaN      NaN   \n",
       "3   ...        5.0      7.0       7.0     7.0     7.0      NaN      NaN   \n",
       "4   ...        5.0      7.0       7.0     7.0     7.0      NaN      NaN   \n",
       "\n",
       "   intel5_3  fun5_3  amb5_3  \n",
       "0       NaN     NaN     NaN  \n",
       "1       NaN     NaN     NaN  \n",
       "2       NaN     NaN     NaN  \n",
       "3       NaN     NaN     NaN  \n",
       "4       NaN     NaN     NaN  \n",
       "\n",
       "[5 rows x 195 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from sklearn import ensemble\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "raw_data = pd.read_csv('./data/speed_dating.csv', encoding=\"ISO-8859-1\")\n",
    "print(raw_data.shape[0], 'Rows')\n",
    "print(raw_data.shape[1], 'Columns')\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* iid -- 551 Unique values\n",
      "* id -- 23 Unique values\n",
      "     # NaNs: 1 - 0.01 % NaN\n",
      "* gender -- 2 Unique values\n",
      "* idg -- 44 Unique values\n",
      "* condtn -- 2 Unique values\n",
      "* wave -- 21 Unique values\n",
      "* round -- 15 Unique values\n",
      "* position -- 22 Unique values\n",
      "* positin1 -- 23 Unique values\n",
      "     # NaNs: 1846 - 22.03 % NaN\n",
      "* order -- 22 Unique values\n",
      "* partner -- 22 Unique values\n",
      "* pid -- 552 Unique values\n",
      "     # NaNs: 10 - 0.12 % NaN\n",
      "* match -- 2 Unique values\n",
      "* int_corr -- 156 Unique values\n",
      "     # NaNs: 158 - 1.89 % NaN\n",
      "* samerace -- 2 Unique values\n",
      "* age_o -- 25 Unique values\n",
      "     # NaNs: 104 - 1.24 % NaN\n",
      "* race_o -- 6 Unique values\n",
      "     # NaNs: 73 - 0.87 % NaN\n",
      "* pf_o_att -- 95 Unique values\n",
      "     # NaNs: 89 - 1.06 % NaN\n",
      "* pf_o_sin -- 79 Unique values\n",
      "     # NaNs: 89 - 1.06 % NaN\n",
      "* pf_o_int -- 66 Unique values\n",
      "     # NaNs: 89 - 1.06 % NaN\n",
      "* pf_o_fun -- 72 Unique values\n",
      "     # NaNs: 98 - 1.17 % NaN\n",
      "* pf_o_amb -- 83 Unique values\n",
      "     # NaNs: 107 - 1.28 % NaN\n",
      "* pf_o_sha -- 86 Unique values\n",
      "     # NaNs: 129 - 1.54 % NaN\n",
      "* dec_o -- 2 Unique values\n",
      "* attr_o -- 19 Unique values\n",
      "     # NaNs: 212 - 2.53 % NaN\n",
      "* sinc_o -- 15 Unique values\n",
      "     # NaNs: 287 - 3.43 % NaN\n",
      "* intel_o -- 18 Unique values\n",
      "     # NaNs: 306 - 3.65 % NaN\n",
      "* fun_o -- 18 Unique values\n",
      "     # NaNs: 360 - 4.3 % NaN\n",
      "* amb_o -- 16 Unique values\n",
      "     # NaNs: 722 - 8.62 % NaN\n",
      "* shar_o -- 16 Unique values\n",
      "     # NaNs: 1076 - 12.84 % NaN\n",
      "* like_o -- 19 Unique values\n",
      "     # NaNs: 250 - 2.98 % NaN\n",
      "* prob_o -- 20 Unique values\n",
      "     # NaNs: 318 - 3.8 % NaN\n",
      "* met_o -- 8 Unique values\n",
      "     # NaNs: 385 - 4.6 % NaN\n",
      "* age -- 25 Unique values\n",
      "     # NaNs: 95 - 1.13 % NaN\n",
      "* field -- 260 Unique values\n",
      "     # NaNs: 63 - 0.75 % NaN\n",
      "* field_cd -- 19 Unique values\n",
      "     # NaNs: 82 - 0.98 % NaN\n",
      "* undergra -- 242 Unique values\n",
      "     # NaNs: 3464 - 41.35 % NaN\n",
      "* mn_sat -- 69 Unique values\n",
      "     # NaNs: 5245 - 62.6 % NaN\n",
      "* tuition -- 116 Unique values\n",
      "     # NaNs: 4795 - 57.23 % NaN\n",
      "* race -- 6 Unique values\n",
      "     # NaNs: 63 - 0.75 % NaN\n",
      "* imprace -- 12 Unique values\n",
      "     # NaNs: 79 - 0.94 % NaN\n",
      "* imprelig -- 11 Unique values\n",
      "     # NaNs: 79 - 0.94 % NaN\n",
      "* from -- 270 Unique values\n",
      "     # NaNs: 79 - 0.94 % NaN\n",
      "* zipcode -- 410 Unique values\n",
      "     # NaNs: 1064 - 12.7 % NaN\n",
      "* income -- 262 Unique values\n",
      "     # NaNs: 4099 - 48.93 % NaN\n",
      "* goal -- 7 Unique values\n",
      "     # NaNs: 79 - 0.94 % NaN\n",
      "* date -- 8 Unique values\n",
      "     # NaNs: 97 - 1.16 % NaN\n",
      "* go_out -- 8 Unique values\n",
      "     # NaNs: 79 - 0.94 % NaN\n",
      "* career -- 368 Unique values\n",
      "     # NaNs: 89 - 1.06 % NaN\n",
      "* career_c -- 18 Unique values\n",
      "     # NaNs: 138 - 1.65 % NaN\n",
      "* sports -- 11 Unique values\n",
      "     # NaNs: 79 - 0.94 % NaN\n",
      "* tvsports -- 11 Unique values\n",
      "     # NaNs: 79 - 0.94 % NaN\n",
      "* exercise -- 11 Unique values\n",
      "     # NaNs: 79 - 0.94 % NaN\n",
      "* dining -- 11 Unique values\n",
      "     # NaNs: 79 - 0.94 % NaN\n",
      "* museums -- 12 Unique values\n",
      "     # NaNs: 79 - 0.94 % NaN\n",
      "* art -- 12 Unique values\n",
      "     # NaNs: 79 - 0.94 % NaN\n",
      "* hiking -- 12 Unique values\n",
      "     # NaNs: 79 - 0.94 % NaN\n",
      "* gaming -- 13 Unique values\n",
      "     # NaNs: 79 - 0.94 % NaN\n",
      "* clubbing -- 12 Unique values\n",
      "     # NaNs: 79 - 0.94 % NaN\n",
      "* reading -- 12 Unique values\n",
      "     # NaNs: 79 - 0.94 % NaN\n",
      "* tv -- 11 Unique values\n",
      "     # NaNs: 79 - 0.94 % NaN\n",
      "* theater -- 12 Unique values\n",
      "     # NaNs: 79 - 0.94 % NaN\n",
      "* movies -- 11 Unique values\n",
      "     # NaNs: 79 - 0.94 % NaN\n",
      "* concerts -- 12 Unique values\n",
      "     # NaNs: 79 - 0.94 % NaN\n",
      "* music -- 11 Unique values\n",
      "     # NaNs: 79 - 0.94 % NaN\n",
      "* shopping -- 11 Unique values\n",
      "     # NaNs: 79 - 0.94 % NaN\n",
      "* yoga -- 12 Unique values\n",
      "     # NaNs: 79 - 0.94 % NaN\n",
      "* exphappy -- 11 Unique values\n",
      "     # NaNs: 101 - 1.21 % NaN\n",
      "* expnum -- 19 Unique values\n",
      "     # NaNs: 6578 - 78.52 % NaN\n",
      "* attr1_1 -- 95 Unique values\n",
      "     # NaNs: 79 - 0.94 % NaN\n",
      "* sinc1_1 -- 79 Unique values\n",
      "     # NaNs: 79 - 0.94 % NaN\n",
      "* intel1_1 -- 66 Unique values\n",
      "     # NaNs: 79 - 0.94 % NaN\n",
      "* fun1_1 -- 72 Unique values\n",
      "     # NaNs: 89 - 1.06 % NaN\n",
      "* amb1_1 -- 83 Unique values\n",
      "     # NaNs: 99 - 1.18 % NaN\n",
      "* shar1_1 -- 86 Unique values\n",
      "     # NaNs: 121 - 1.44 % NaN\n",
      "* attr4_1 -- 34 Unique values\n",
      "     # NaNs: 1889 - 22.55 % NaN\n",
      "* sinc4_1 -- 25 Unique values\n",
      "     # NaNs: 1889 - 22.55 % NaN\n",
      "* intel4_1 -- 25 Unique values\n",
      "     # NaNs: 1889 - 22.55 % NaN\n",
      "* fun4_1 -- 23 Unique values\n",
      "     # NaNs: 1889 - 22.55 % NaN\n",
      "* amb4_1 -- 26 Unique values\n",
      "     # NaNs: 1889 - 22.55 % NaN\n",
      "* shar4_1 -- 26 Unique values\n",
      "     # NaNs: 1911 - 22.81 % NaN\n",
      "* attr2_1 -- 88 Unique values\n",
      "     # NaNs: 79 - 0.94 % NaN\n",
      "* sinc2_1 -- 81 Unique values\n",
      "     # NaNs: 79 - 0.94 % NaN\n",
      "* intel2_1 -- 79 Unique values\n",
      "     # NaNs: 79 - 0.94 % NaN\n",
      "* fun2_1 -- 75 Unique values\n",
      "     # NaNs: 79 - 0.94 % NaN\n",
      "* amb2_1 -- 78 Unique values\n",
      "     # NaNs: 89 - 1.06 % NaN\n",
      "* shar2_1 -- 74 Unique values\n",
      "     # NaNs: 89 - 1.06 % NaN\n",
      "* attr3_1 -- 10 Unique values\n",
      "     # NaNs: 105 - 1.25 % NaN\n",
      "* sinc3_1 -- 10 Unique values\n",
      "     # NaNs: 105 - 1.25 % NaN\n",
      "* fun3_1 -- 10 Unique values\n",
      "     # NaNs: 105 - 1.25 % NaN\n",
      "* intel3_1 -- 9 Unique values\n",
      "     # NaNs: 105 - 1.25 % NaN\n",
      "* amb3_1 -- 10 Unique values\n",
      "     # NaNs: 105 - 1.25 % NaN\n",
      "* attr5_1 -- 10 Unique values\n",
      "     # NaNs: 3472 - 41.44 % NaN\n",
      "* sinc5_1 -- 11 Unique values\n",
      "     # NaNs: 3472 - 41.44 % NaN\n",
      "* intel5_1 -- 9 Unique values\n",
      "     # NaNs: 3472 - 41.44 % NaN\n",
      "* fun5_1 -- 10 Unique values\n",
      "     # NaNs: 3472 - 41.44 % NaN\n",
      "* amb5_1 -- 11 Unique values\n",
      "     # NaNs: 3472 - 41.44 % NaN\n",
      "* dec -- 2 Unique values\n",
      "* attr -- 18 Unique values\n",
      "     # NaNs: 202 - 2.41 % NaN\n",
      "* sinc -- 15 Unique values\n",
      "     # NaNs: 277 - 3.31 % NaN\n",
      "* intel -- 18 Unique values\n",
      "     # NaNs: 296 - 3.53 % NaN\n",
      "* fun -- 17 Unique values\n",
      "     # NaNs: 350 - 4.18 % NaN\n",
      "* amb -- 16 Unique values\n",
      "     # NaNs: 712 - 8.5 % NaN\n",
      "* shar -- 16 Unique values\n",
      "     # NaNs: 1067 - 12.74 % NaN\n",
      "* like -- 19 Unique values\n",
      "     # NaNs: 240 - 2.86 % NaN\n",
      "* prob -- 20 Unique values\n",
      "     # NaNs: 309 - 3.69 % NaN\n",
      "* met -- 9 Unique values\n",
      "     # NaNs: 375 - 4.48 % NaN\n",
      "* match_es -- 18 Unique values\n",
      "     # NaNs: 1173 - 14.0 % NaN\n",
      "* attr1_s -- 74 Unique values\n",
      "     # NaNs: 4282 - 51.11 % NaN\n",
      "* sinc1_s -- 68 Unique values\n",
      "     # NaNs: 4282 - 51.11 % NaN\n",
      "* intel1_s -- 65 Unique values\n",
      "     # NaNs: 4282 - 51.11 % NaN\n",
      "* fun1_s -- 65 Unique values\n",
      "     # NaNs: 4282 - 51.11 % NaN\n",
      "* amb1_s -- 77 Unique values\n",
      "     # NaNs: 4282 - 51.11 % NaN\n",
      "* shar1_s -- 77 Unique values\n",
      "     # NaNs: 4282 - 51.11 % NaN\n",
      "* attr3_s -- 10 Unique values\n",
      "     # NaNs: 4378 - 52.26 % NaN\n",
      "* sinc3_s -- 12 Unique values\n",
      "     # NaNs: 4378 - 52.26 % NaN\n",
      "* intel3_s -- 9 Unique values\n",
      "     # NaNs: 4378 - 52.26 % NaN\n",
      "* fun3_s -- 9 Unique values\n",
      "     # NaNs: 4378 - 52.26 % NaN\n",
      "* amb3_s -- 10 Unique values\n",
      "     # NaNs: 4378 - 52.26 % NaN\n",
      "* satis_2 -- 11 Unique values\n",
      "     # NaNs: 915 - 10.92 % NaN\n",
      "* length -- 4 Unique values\n",
      "     # NaNs: 915 - 10.92 % NaN\n",
      "* numdat_2 -- 4 Unique values\n",
      "     # NaNs: 945 - 11.28 % NaN\n",
      "* attr7_2 -- 17 Unique values\n",
      "     # NaNs: 6394 - 76.32 % NaN\n",
      "* sinc7_2 -- 17 Unique values\n",
      "     # NaNs: 6423 - 76.67 % NaN\n",
      "* intel7_2 -- 17 Unique values\n",
      "     # NaNs: 6394 - 76.32 % NaN\n",
      "* fun7_2 -- 17 Unique values\n",
      "     # NaNs: 6394 - 76.32 % NaN\n",
      "* amb7_2 -- 11 Unique values\n",
      "     # NaNs: 6423 - 76.67 % NaN\n",
      "* shar7_2 -- 15 Unique values\n",
      "     # NaNs: 6404 - 76.44 % NaN\n",
      "* attr1_2 -- 78 Unique values\n",
      "     # NaNs: 933 - 11.14 % NaN\n",
      "* sinc1_2 -- 72 Unique values\n",
      "     # NaNs: 915 - 10.92 % NaN\n",
      "* intel1_2 -- 68 Unique values\n",
      "     # NaNs: 915 - 10.92 % NaN\n",
      "* fun1_2 -- 75 Unique values\n",
      "     # NaNs: 915 - 10.92 % NaN\n",
      "* amb1_2 -- 74 Unique values\n",
      "     # NaNs: 915 - 10.92 % NaN\n",
      "* shar1_2 -- 83 Unique values\n",
      "     # NaNs: 915 - 10.92 % NaN\n",
      "* attr4_2 -- 28 Unique values\n",
      "     # NaNs: 2603 - 31.07 % NaN\n",
      "* sinc4_2 -- 23 Unique values\n",
      "     # NaNs: 2603 - 31.07 % NaN\n",
      "* intel4_2 -- 26 Unique values\n",
      "     # NaNs: 2603 - 31.07 % NaN\n",
      "* fun4_2 -- 23 Unique values\n",
      "     # NaNs: 2603 - 31.07 % NaN\n",
      "* amb4_2 -- 25 Unique values\n",
      "     # NaNs: 2603 - 31.07 % NaN\n",
      "* shar4_2 -- 23 Unique values\n",
      "     # NaNs: 2603 - 31.07 % NaN\n",
      "* attr2_2 -- 82 Unique values\n",
      "     # NaNs: 2603 - 31.07 % NaN\n",
      "* sinc2_2 -- 68 Unique values\n",
      "     # NaNs: 2603 - 31.07 % NaN\n",
      "* intel2_2 -- 70 Unique values\n",
      "     # NaNs: 2603 - 31.07 % NaN\n",
      "* fun2_2 -- 62 Unique values\n",
      "     # NaNs: 2603 - 31.07 % NaN\n",
      "* amb2_2 -- 77 Unique values\n",
      "     # NaNs: 2603 - 31.07 % NaN\n",
      "* shar2_2 -- 65 Unique values\n",
      "     # NaNs: 2603 - 31.07 % NaN\n",
      "* attr3_2 -- 10 Unique values\n",
      "     # NaNs: 915 - 10.92 % NaN\n",
      "* sinc3_2 -- 10 Unique values\n",
      "     # NaNs: 915 - 10.92 % NaN\n",
      "* intel3_2 -- 8 Unique values\n",
      "     # NaNs: 915 - 10.92 % NaN\n",
      "* fun3_2 -- 11 Unique values\n",
      "     # NaNs: 915 - 10.92 % NaN\n",
      "* amb3_2 -- 10 Unique values\n",
      "     # NaNs: 915 - 10.92 % NaN\n",
      "* attr5_2 -- 10 Unique values\n",
      "     # NaNs: 4001 - 47.76 % NaN\n",
      "* sinc5_2 -- 10 Unique values\n",
      "     # NaNs: 4001 - 47.76 % NaN\n",
      "* intel5_2 -- 9 Unique values\n",
      "     # NaNs: 4001 - 47.76 % NaN\n",
      "* fun5_2 -- 10 Unique values\n",
      "     # NaNs: 4001 - 47.76 % NaN\n",
      "* amb5_2 -- 9 Unique values\n",
      "     # NaNs: 4001 - 47.76 % NaN\n",
      "* you_call -- 10 Unique values\n",
      "     # NaNs: 4404 - 52.57 % NaN\n",
      "* them_cal -- 9 Unique values\n",
      "     # NaNs: 4404 - 52.57 % NaN\n",
      "* date_3 -- 3 Unique values\n",
      "     # NaNs: 4404 - 52.57 % NaN\n",
      "* numdat_3 -- 7 Unique values\n",
      "     # NaNs: 6882 - 82.14 % NaN\n",
      "* num_in_3 -- 5 Unique values\n",
      "     # NaNs: 7710 - 92.03 % NaN\n",
      "* attr1_3 -- 57 Unique values\n",
      "     # NaNs: 4404 - 52.57 % NaN\n",
      "* sinc1_3 -- 48 Unique values\n",
      "     # NaNs: 4404 - 52.57 % NaN\n",
      "* intel1_3 -- 45 Unique values\n",
      "     # NaNs: 4404 - 52.57 % NaN\n",
      "* fun1_3 -- 54 Unique values\n",
      "     # NaNs: 4404 - 52.57 % NaN\n",
      "* amb1_3 -- 57 Unique values\n",
      "     # NaNs: 4404 - 52.57 % NaN\n",
      "* shar1_3 -- 54 Unique values\n",
      "     # NaNs: 4404 - 52.57 % NaN\n",
      "* attr7_3 -- 22 Unique values\n",
      "     # NaNs: 6362 - 75.94 % NaN\n",
      "* sinc7_3 -- 14 Unique values\n",
      "     # NaNs: 6362 - 75.94 % NaN\n",
      "* intel7_3 -- 15 Unique values\n",
      "     # NaNs: 6362 - 75.94 % NaN\n",
      "* fun7_3 -- 17 Unique values\n",
      "     # NaNs: 6362 - 75.94 % NaN\n",
      "* amb7_3 -- 14 Unique values\n",
      "     # NaNs: 6362 - 75.94 % NaN\n",
      "* shar7_3 -- 16 Unique values\n",
      "     # NaNs: 6362 - 75.94 % NaN\n",
      "* attr4_3 -- 24 Unique values\n",
      "     # NaNs: 5419 - 64.68 % NaN\n",
      "* sinc4_3 -- 17 Unique values\n",
      "     # NaNs: 5419 - 64.68 % NaN\n",
      "* intel4_3 -- 17 Unique values\n",
      "     # NaNs: 5419 - 64.68 % NaN\n",
      "* fun4_3 -- 16 Unique values\n",
      "     # NaNs: 5419 - 64.68 % NaN\n",
      "* amb4_3 -- 21 Unique values\n",
      "     # NaNs: 5419 - 64.68 % NaN\n",
      "* shar4_3 -- 17 Unique values\n",
      "     # NaNs: 5419 - 64.68 % NaN\n",
      "* attr2_3 -- 24 Unique values\n",
      "     # NaNs: 5419 - 64.68 % NaN\n",
      "* sinc2_3 -- 14 Unique values\n",
      "     # NaNs: 5419 - 64.68 % NaN\n",
      "* intel2_3 -- 18 Unique values\n",
      "     # NaNs: 5419 - 64.68 % NaN\n",
      "* fun2_3 -- 17 Unique values\n",
      "     # NaNs: 5419 - 64.68 % NaN\n",
      "* amb2_3 -- 18 Unique values\n",
      "     # NaNs: 5419 - 64.68 % NaN\n",
      "* shar2_3 -- 13 Unique values\n",
      "     # NaNs: 6362 - 75.94 % NaN\n",
      "* attr3_3 -- 11 Unique values\n",
      "     # NaNs: 4404 - 52.57 % NaN\n",
      "* sinc3_3 -- 11 Unique values\n",
      "     # NaNs: 4404 - 52.57 % NaN\n",
      "* intel3_3 -- 10 Unique values\n",
      "     # NaNs: 4404 - 52.57 % NaN\n",
      "* fun3_3 -- 11 Unique values\n",
      "     # NaNs: 4404 - 52.57 % NaN\n",
      "* amb3_3 -- 12 Unique values\n",
      "     # NaNs: 4404 - 52.57 % NaN\n",
      "* attr5_3 -- 10 Unique values\n",
      "     # NaNs: 6362 - 75.94 % NaN\n",
      "* sinc5_3 -- 10 Unique values\n",
      "     # NaNs: 6362 - 75.94 % NaN\n",
      "* intel5_3 -- 8 Unique values\n",
      "     # NaNs: 6362 - 75.94 % NaN\n",
      "* fun5_3 -- 11 Unique values\n",
      "     # NaNs: 6362 - 75.94 % NaN\n",
      "* amb5_3 -- 10 Unique values\n",
      "     # NaNs: 6362 - 75.94 % NaN\n"
     ]
    }
   ],
   "source": [
    "def get_col_descriptions(df):\n",
    "    for col in df.columns:\n",
    "        if col != 'iid' and col != 'pid':\n",
    "            print('*', col, '--', len(df[col].unique()), 'Unique values') #, df[col].value_counts().sort_index())\n",
    "        else:\n",
    "            print('*', col, '--', len(df[col].unique()), 'Unique values') #, (df[col].unique()))\n",
    "            \n",
    "        if df[col].isnull().sum() > 0:\n",
    "            num_nans = df[col].isnull().sum()\n",
    "            print('     # NaNs:', num_nans, '-', round(num_nans/df.shape[0] * 100, 2), '% NaN')\n",
    "            \n",
    "\n",
    "get_col_descriptions(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match</th>\n",
       "      <th>attr1_1</th>\n",
       "      <th>sinc1_1</th>\n",
       "      <th>intel1_1</th>\n",
       "      <th>fun1_1</th>\n",
       "      <th>amb1_1</th>\n",
       "      <th>shar1_1</th>\n",
       "      <th>pf_o_att</th>\n",
       "      <th>pf_o_sin</th>\n",
       "      <th>pf_o_int</th>\n",
       "      <th>...</th>\n",
       "      <th>pf_o_amb</th>\n",
       "      <th>pf_o_sha</th>\n",
       "      <th>attr_o</th>\n",
       "      <th>sinc_o</th>\n",
       "      <th>intel_o</th>\n",
       "      <th>fun_o</th>\n",
       "      <th>attr</th>\n",
       "      <th>sinc</th>\n",
       "      <th>intel</th>\n",
       "      <th>fun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.19</td>\n",
       "      <td>...</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   match  attr1_1  sinc1_1  intel1_1  fun1_1  amb1_1  shar1_1  pf_o_att  \\\n",
       "0      0     0.15      0.2       0.2    0.15    0.15     0.15      0.35   \n",
       "1      0     0.15      0.2       0.2    0.15    0.15     0.15      0.60   \n",
       "2      1     0.15      0.2       0.2    0.15    0.15     0.15      0.19   \n",
       "3      1     0.15      0.2       0.2    0.15    0.15     0.15      0.30   \n",
       "4      1     0.15      0.2       0.2    0.15    0.15     0.15      0.30   \n",
       "\n",
       "   pf_o_sin  pf_o_int ...   pf_o_amb  pf_o_sha  attr_o  sinc_o  intel_o  \\\n",
       "0      0.20      0.20 ...       0.00      0.05     0.6     0.8      0.8   \n",
       "1      0.00      0.00 ...       0.00      0.00     0.7     0.8      1.0   \n",
       "2      0.18      0.19 ...       0.14      0.12     1.0     1.0      1.0   \n",
       "3      0.05      0.15 ...       0.05      0.05     0.7     0.8      0.9   \n",
       "4      0.10      0.20 ...       0.10      0.20     0.8     0.7      0.9   \n",
       "\n",
       "   fun_o  attr  sinc  intel  fun  \n",
       "0    0.8   0.6   0.9    0.7  0.7  \n",
       "1    0.7   0.7   0.8    0.7  0.8  \n",
       "2    1.0   0.5   0.8    0.9  0.8  \n",
       "3    0.8   0.7   0.6    0.8  0.7  \n",
       "4    0.6   0.5   0.6    0.7  0.7  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = raw_data.copy()\n",
    "\n",
    "my_prefs = list(df.columns[69:75])\n",
    "partners_prefs = list(df.columns[17:23])\n",
    "me_rated = list(df.columns[24:28]) # 30\n",
    "partner_rated = list(df.columns[98:102]) # 104\n",
    "\n",
    "df[my_prefs] = df[my_prefs].apply(lambda x: round(x / 100, 2))\n",
    "df[partners_prefs] = df[partners_prefs].apply(lambda x: round(x / 100, 2))\n",
    "\n",
    "df[me_rated] = df[me_rated].apply(lambda x: round(x / 10, 2))\n",
    "df[partner_rated] = df[partner_rated].apply(lambda x: round(x / 10, 2))\n",
    "\n",
    "cols_of_interest = ['match'] + my_prefs + partners_prefs + me_rated + partner_rated\n",
    "df = df[cols_of_interest]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7378 rows left\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match</th>\n",
       "      <th>attr1_1</th>\n",
       "      <th>sinc1_1</th>\n",
       "      <th>intel1_1</th>\n",
       "      <th>fun1_1</th>\n",
       "      <th>amb1_1</th>\n",
       "      <th>shar1_1</th>\n",
       "      <th>pf_o_att</th>\n",
       "      <th>pf_o_sin</th>\n",
       "      <th>pf_o_int</th>\n",
       "      <th>...</th>\n",
       "      <th>pf_o_amb</th>\n",
       "      <th>pf_o_sha</th>\n",
       "      <th>attr_o</th>\n",
       "      <th>sinc_o</th>\n",
       "      <th>intel_o</th>\n",
       "      <th>fun_o</th>\n",
       "      <th>attr</th>\n",
       "      <th>sinc</th>\n",
       "      <th>intel</th>\n",
       "      <th>fun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.19</td>\n",
       "      <td>...</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   match  attr1_1  sinc1_1  intel1_1  fun1_1  amb1_1  shar1_1  pf_o_att  \\\n",
       "0      0     0.15      0.2       0.2    0.15    0.15     0.15      0.35   \n",
       "1      0     0.15      0.2       0.2    0.15    0.15     0.15      0.60   \n",
       "2      1     0.15      0.2       0.2    0.15    0.15     0.15      0.19   \n",
       "3      1     0.15      0.2       0.2    0.15    0.15     0.15      0.30   \n",
       "4      1     0.15      0.2       0.2    0.15    0.15     0.15      0.30   \n",
       "\n",
       "   pf_o_sin  pf_o_int ...   pf_o_amb  pf_o_sha  attr_o  sinc_o  intel_o  \\\n",
       "0      0.20      0.20 ...       0.00      0.05     0.6     0.8      0.8   \n",
       "1      0.00      0.00 ...       0.00      0.00     0.7     0.8      1.0   \n",
       "2      0.18      0.19 ...       0.14      0.12     1.0     1.0      1.0   \n",
       "3      0.05      0.15 ...       0.05      0.05     0.7     0.8      0.9   \n",
       "4      0.10      0.20 ...       0.10      0.20     0.8     0.7      0.9   \n",
       "\n",
       "   fun_o  attr  sinc  intel  fun  \n",
       "0    0.8   0.6   0.9    0.7  0.7  \n",
       "1    0.7   0.7   0.8    0.7  0.8  \n",
       "2    1.0   0.5   0.8    0.9  0.8  \n",
       "3    0.8   0.7   0.6    0.8  0.7  \n",
       "4    0.6   0.5   0.6    0.7  0.7  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna(axis=0)\n",
    "print(df.shape[0], 'rows left')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1288 matches; 6090 non-matches\n",
      "82.54% non-matches\n"
     ]
    }
   ],
   "source": [
    "matches = df[df['match'] == 1]\n",
    "non_matches = df[df['match'] == 0]\n",
    "\n",
    "num_matches = matches.shape[0]\n",
    "num_non_matches = non_matches.shape[0]\n",
    "percent_majority = round(num_non_matches / df.shape[0] * 100, 2)\n",
    "\n",
    "print(('{} matches; {} non-matches\\n{}% non-matches').format(num_matches, num_non_matches, percent_majority))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Must Over-Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function _ratio_float is deprecated; Use a float for 'ratio' is deprecated from version 0.2. The support will be removed in 0.4. Use a dict, str, or a callable instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "X = df.loc[:, df.columns != 'match']\n",
    "Y = df['match']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=1)\n",
    "\n",
    "sm = SMOTE(random_state=1, ratio = 1.0)\n",
    "X_train_res, Y_train_res = sm.fit_sample(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model outcome of interest\n",
    "\n",
    "You should try several different approaches and really work to tune a variety of models before using the model evaluation techniques to choose what you consider to be the best performer. Make sure to think about explanatory versus predictive power and experiment with both.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RÂ² for train: 0.7382974878004699\n",
      "RÂ² for test: 0.7447154471544716\n",
      "\n",
      " predicted     0    1   All\n",
      "actual                    \n",
      "0          1121  387  1508\n",
      "1            84  253   337\n",
      "All        1205  640  1845\n",
      "\n",
      "Type I errors: 20.98%\n",
      "Type II errors: 4.55%\n",
      "\n",
      "Precision: 39.53%\n",
      "Recall: 75.07%\n",
      "\n",
      "Coefficients: [[-1.31550779 -1.36787597  1.04426665  0.77961095 -1.2913668   0.39804416\n",
      "  -2.17687636 -1.4895599   0.         -0.81759189 -1.62205306 -1.22683141\n",
      "   3.32755173 -0.3695101   0.52404822  3.02621084  3.35707152  0.0231907\n",
      "   0.1959008   2.83009353]]\n"
     ]
    }
   ],
   "source": [
    "def fit_and_train(model):\n",
    "    model_fit = model.fit(X_train_res, Y_train_res)\n",
    "    model_score_train = model.score(X_train, Y_train)\n",
    "    print('RÂ² for train:', model_score_train)\n",
    "    \n",
    "    model_score_test = model.score(X_test, Y_test)\n",
    "    print('RÂ² for test:', model_score_test)\n",
    "    \n",
    "    test_crosstab = pd.crosstab(Y_test, model_fit.predict(X_test), rownames=['actual'], colnames=['predicted'], margins=True)\n",
    "    print('\\n', test_crosstab)\n",
    "    \n",
    "    tI_errors = test_crosstab.loc[0,1] / test_crosstab.loc['All','All'] * 100\n",
    "    tII_errors = test_crosstab.loc[1,0] / test_crosstab.loc['All','All'] * 100\n",
    "    print(('\\nType I errors: {}%\\nType II errors: {}%\\n').format(round(tI_errors, 2), round(tII_errors, 2)))\n",
    "\n",
    "    precision = test_crosstab.loc[1,1] / test_crosstab.loc['All', 1] * 100 \n",
    "    recall = test_crosstab.loc[1,1] / test_crosstab.loc[1,'All'] * 100 \n",
    "    print(('Precision: {}%\\nRecall: {}%').format(round(precision, 2), round(recall, 2)))\n",
    "    \n",
    "    \n",
    "    if hasattr(model_fit, 'coef_'):\n",
    "        print('\\nCoefficients:', model_fit.coef_)\n",
    "\n",
    "lasso = linear_model.LogisticRegression(penalty='l1', C=10) \n",
    "fit_and_train(lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RÂ² for train: 0.872582685703958\n",
      "RÂ² for test: 0.8525745257452575\n",
      "\n",
      " predicted     0    1   All\n",
      "actual                    \n",
      "0          1427   81  1508\n",
      "1           191  146   337\n",
      "All        1618  227  1845\n",
      "\n",
      "Type I errors: 4.39%\n",
      "Type II errors: 10.35%\n",
      "\n",
      "Precision: 64.32%\n",
      "Recall: 43.32%\n"
     ]
    }
   ],
   "source": [
    "gbm = ensemble.GradientBoostingClassifier(n_estimators=500, max_depth=2, loss='deviance')\n",
    "fit_and_train(gbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RÂ² for train: 0.731610337972167\n",
      "RÂ² for test: 0.7338753387533875\n",
      "\n",
      " predicted     0    1   All\n",
      "actual                    \n",
      "0          1097  411  1508\n",
      "1            80  257   337\n",
      "All        1177  668  1845\n",
      "\n",
      "Type I errors: 22.28%\n",
      "Type II errors: 4.34%\n",
      "\n",
      "Precision: 38.47%\n",
      "Recall: 76.26%\n",
      "\n",
      "Coefficients: [[-0.88183812 -1.08612012  1.15350421  0.75641592 -0.51531128  0.38501539\n",
      "  -0.9029509  -0.41569176  1.13555936  0.37477409 -0.3715132  -0.29081559\n",
      "   2.66566971 -0.25432352  0.26543576  2.68679467  2.73443596  0.10990641\n",
      "   0.08485801  2.41392559]]\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(kernel='linear', probability=True)\n",
    "fit_and_train(svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RÂ² for train: 0.9931321163925537\n",
      "RÂ² for test: 0.8238482384823849\n",
      "\n",
      " predicted     0    1   All\n",
      "actual                    \n",
      "0          1403  105  1508\n",
      "1           220  117   337\n",
      "All        1623  222  1845\n",
      "\n",
      "Type I errors: 5.69%\n",
      "Type II errors: 11.92%\n",
      "\n",
      "Precision: 52.7%\n",
      "Recall: 34.72%\n"
     ]
    }
   ],
   "source": [
    "rfc = ensemble.RandomForestClassifier()\n",
    "fit_and_train(rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb = BernoulliNB()\n",
    "fit_and_train(bnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deliverables\n",
    "\n",
    "Prepare a slide deck and 15 minute presentation that guides viewers through your model. Be sure to cover a few specific things:\n",
    "\n",
    "- A specified research question your model addresses\n",
    "- How you chose your model specification and what alternatives you compared it to\n",
    "- The practical uses of your model for an audience of interest\n",
    "- Any weak points or shortcomings of your model\n",
    "\n",
    "You'll be presenting this slide deck live to a group as the culmination of your work in the last 2 supervised learning units. As a secondary matter, your slides and/or the Jupyter notebook you use or adapt them into should be worthy of inclusion as examples of your work product when applying to jobs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
